{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Isochrones\n",
    "Run batch Conveyal queries for multiple origins\n",
    "\n",
    "Setup requires:\n",
    " - A current Conveyal token (e.g. 'bearer 1234abcd...') saved at `config/.auth`. This token can be obtained with [the network tab of your browser's dev tools](https://developers.google.com/web/tools/chrome-devtools/network/), by logging into your Conveyal account, navigating to a project, finding a network request to api.conveyal.com, and inspecting the request Authorization headers.\n",
    " - An appropriate analysis request template, copied as JSON from the analysis panel of the Conveyal user interface. Relevant properties include `destinationPointSetIds`, `projectId` (id of the project in Conveyal), `regionId`, and `modificationIds`\n",
    " - An array of origin points, as a JSON array with properties \"name\", \"fromLat\", and \"fromLon\" saved to `config/origins.json`.\n",
    "\n",
    "After the setup cell in this notebook, there are cells to: \n",
    " - Create a .geojson file of isochrones for each origin. Each file has features for default travel time cutoffs (0 minutes to 90 minutes, at 15 minute increments) and percentiles.\n",
    " - Create a .csv file of accessibility statistics for each origin. These statistics will based on \"cutoffs\" at minute increments up to 120 minutes, for the [decay function](https://docs.conveyal.com/learn-more/decay-functions), travel time percentiles, and destination pointsets (opportunity datasets) specified in the analysis request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import numpy\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import geojsoncontour\n",
    "import geojson\n",
    "import rasterio\n",
    "import shapely_geojson\n",
    "from shapely.geometry import mapping, shape, MultiPolygon\n",
    "from struct import unpack\n",
    "\n",
    "url = 'https://api.conveyal.com/api/analysis'\n",
    "\n",
    "# Authorization header copied from DevTools Network request\n",
    "token = open('config/.auth').readline().strip()\n",
    "\n",
    "# Copy from Advanced Settings in the analysis panel\n",
    "# Ensure that the scenario, variantNumber, and other parameters are set correctly\n",
    "profileRequest = json.load(open('config/profile-requests/london-demo-2.json'))\n",
    "\n",
    "# Load from a JSON array with properties \"name\", \"fromLat\", and \"fromLon\" for each point\n",
    "origins = json.load(open('config/origins.json'))\n",
    "\n",
    "isochroneIntervals = range(0, 90, 15)\n",
    "\n",
    "percentileValues = profileRequest.percentiles\n",
    "\n",
    "headers = {\n",
    "    'Authorization': token\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download geotiffs and process isochrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers['Accept'] = 'image/tiff'\n",
    "\n",
    "# Loop over origins\n",
    "for origin in origins:\n",
    "    originName = origin['name']\n",
    "    profileRequest['fromLat'] = origin['fromLat']\n",
    "    profileRequest['fromLon'] = origin['fromLon']\n",
    "    \n",
    "    print('Processing ' + originName)\n",
    "    \n",
    "    # Request a tiff from Conveyal Analysis\n",
    "    r = requests.post(url, headers = headers, json = profileRequest, verify = False)\n",
    "    \n",
    "    if r.status_code == 202:\n",
    "        print('Routing engine starting, try again in a few minutes.')\n",
    "    \n",
    "    elif r.status_code == 403:\n",
    "        print('Unauthorized access. Your authorization token may be invalid or expired.')\n",
    "        \n",
    "    elif r.status_code != 200:\n",
    "        print('Error: ' + r.text)\n",
    "        \n",
    "    else:\n",
    "        # Save response from Conveyal Analysis to a local .tiff file\n",
    "        with open(originName + '.tiff', 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=128):\n",
    "                f.write(chunk)\n",
    "                \n",
    "        f.close()\n",
    "                \n",
    "        tiff = rasterio.open(originName + '.tiff')\n",
    "        print(tiff)\n",
    "        crsEpsg = tiff.crs.to_string()\n",
    "\n",
    "        # Set up tiff processing        \n",
    "        latRange = numpy.arange(tiff.bounds.top, tiff.bounds.bottom, -tiff.res[1])\n",
    "        lonRange = numpy.arange(tiff.bounds.left, tiff.bounds.right, tiff.res[0])\n",
    "\n",
    "        isochroneJson = {\n",
    "            'crs': {'type':'name','properties':{'name': crsEpsg}},\n",
    "            'type': 'FeatureCollection',\n",
    "            'features': []\n",
    "        }    \n",
    "        \n",
    "        figure = plt.figure().add_subplot(111)\n",
    "        \n",
    "        # Loop over percentile values\n",
    "        for percentileIndex in range(0, len(percentileValues)):\n",
    "            print(percentileValues[percentileIndex])\n",
    "            values =  tiff.read(percentileIndex + 1) # GDAL 1-based indexing\n",
    "            values[values == 0] = 120\n",
    "            contourf = figure.contourf(lonRange, latRange, values, levels = isochroneIntervals)\n",
    "            contours = geojsoncontour.contourf_to_geojson(contourf = contourf, ndigits = 3)\n",
    "            contourJson = json.loads(contours)\n",
    "            print(len(contourJson['features']))\n",
    "            \n",
    "            # Loop over the travel time cutoff values \n",
    "            # (one set of features per element of isochrone intervals)\n",
    "            for i in range(len(contourJson['features'])):\n",
    "\n",
    "                feature = contourJson['features'][i]\n",
    "                cutoff = list(isochroneIntervals)[i+1]\n",
    "\n",
    "                isochroneFeature = {\n",
    "                    'type': 'Feature',\n",
    "                    'properties': {\n",
    "                        'minutes': cutoff,\n",
    "                        'percentile': percentileValues[percentileIndex]\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                # The next two steps remove shapes with no coordinates, zero-area artifacts, \n",
    "                # and self-intersections\n",
    "                nextBand = shape({\n",
    "                    'type': 'MultiPolygon', \n",
    "                    'coordinates': list(filter(\n",
    "                        lambda coords: (len(coords) > 0), \n",
    "                        feature['geometry']['coordinates']))\n",
    "                })\n",
    "\n",
    "                nextBand = MultiPolygon(list(filter(lambda poly: (poly.area > 0), nextBand))).buffer(0)\n",
    "\n",
    "                # countourf returns the area between the requested intervals (e.g. a bandreachable in \n",
    "                # between 15 and 30 minutes). Union this band with the previous ones to show the cumulative\n",
    "                # area reachable.\n",
    "                if i > 0:\n",
    "                    nextBand = nextBand.union(shape(isochroneJson['features'][i - 1]['geometry']))\n",
    "\n",
    "                isochroneFeature['geometry'] = json.loads(shapely_geojson.dumps(nextBand))\n",
    "                isochroneJson['features'].append(isochroneFeature)\n",
    "\n",
    "            # Write out the various travel time cutoff and percentile values to a single file per-origin.\n",
    "            with open(originName + '.geojson', 'w') as f:\n",
    "                json.dump(isochroneJson, f)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download accessibility results\n",
    "\n",
    "**NOTE:** Your profile request JSON file *must* have an ID of spatial dataset defined in `destinationPointSetIds` for this section to work. To find a spatial dataset ID, navigate to your spatial dataset and use the `opportunityDatasetId` defined at the end of the URL. For example:\n",
    "\n",
    "URL: `https://analysis.conveyal.com/regions/5f3b4199f0b14a34c61a0653/opportunities?opportunityDatasetId=61b751e1f49a7e2152fa209b`\n",
    "Profile Request JSON entry: `\"destinationPointSetIds\": [\"61b751e1f49a7e2152fa209b\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch the accept header from tiff (used for geotiff above) to json\n",
    "headers['Accept'] = 'application/json'\n",
    "\n",
    "# See https://github.com/conveyal/analysis-ui/blob/dev/lib/actions/analysis/parse-times-data.ts\n",
    "headerEntries = 7\n",
    "bytesPerElement = 4\n",
    "timesGridType = 'ACCESSGR'\n",
    "headerStart = len(timesGridType)\n",
    "headerEnd = headerStart + bytesPerElement * headerEntries\n",
    "\n",
    "combinedAccessibility = {}\n",
    "\n",
    "with open('batch-accessibility.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(['origin', 'percentile', 'cutoff', 'accessibility'])\n",
    "\n",
    "    # Loop over origins\n",
    "    for origin in origins:\n",
    "        originName = origin['name']\n",
    "        combinedAccessibility[originName] = {}\n",
    "        profileRequest['fromLat'] = origin['fromLat']\n",
    "        profileRequest['fromLon'] = origin['fromLon']\n",
    "\n",
    "        print('Processing ' + originName)\n",
    "\n",
    "\n",
    "        # Request a single-point analysis from Conveyal\n",
    "        r = requests.post(url, headers = headers, json = profileRequest, verify = False)\n",
    "\n",
    "        if r.status_code == 202:\n",
    "            print('Routing engine starting, try again in a few minutes.')\n",
    "\n",
    "        elif r.status_code == 403:\n",
    "            print('Unauthorized access. Your authorization token may be invalid or expired.')\n",
    "\n",
    "        elif r.status_code != 200:\n",
    "            print('Error: ' + r.text)\n",
    "\n",
    "        else:\n",
    "            # little-endian, unsigned int\n",
    "            header = unpack('<'+ str(headerEntries) + 'I', r.content[headerStart : headerEnd])\n",
    "            version = header[0]\n",
    "            zoom = header[1]\n",
    "            west = header[2]\n",
    "            north = header[3]\n",
    "            width = header[4]\n",
    "            height = header[5]\n",
    "            depth = header[6]\n",
    "            accessibilityResults = json.loads(r.content[headerEnd + bytesPerElement * height * width * depth :])['accessibility']\n",
    "            for d in range(depth):\n",
    "                percentile = profileRequest['percentiles'][d]\n",
    "                for c in range(120):\n",
    "                    writer.writerow([originName, percentile, c + 1, accessibilityResults[0][d][c]])\n",
    "csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
